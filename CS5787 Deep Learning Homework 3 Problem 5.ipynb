{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5 - Vision Transformers (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minds\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import timm\n",
    "\n",
    "# Load data\n",
    "def load_data_transformer(data_dir):\n",
    "    # Load a pre-trained Swin Transformer\n",
    "    model_name = \"swin_tiny_patch4_window7_224\"\n",
    "    transformer = timm.create_model(model_name, pretrained=True)\n",
    "    # Remove the final classification head\n",
    "    transformer = torch.nn.Sequential(*(list(transformer.children())[:-1]))\n",
    "\n",
    "    # Define image transformations\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    label_to_int = {}\n",
    "    current_label_int = 0\n",
    "\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(data_dir, filename)\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = data_transforms(image)\n",
    "            image = image.unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "            with torch.no_grad():\n",
    "                feature = transformer(image).numpy().flatten()  # Extract features\n",
    "\n",
    "            features.append(feature)\n",
    "            label = filename.split('.')[0].split('_')[0]\n",
    "\n",
    "            if label not in label_to_int:\n",
    "                label_to_int[label] = current_label_int\n",
    "                current_label_int += 1\n",
    "\n",
    "            labels.append(label_to_int[label])\n",
    "\n",
    "    features = normalize(features, axis=1)  # Normalize the features\n",
    "    return np.array(features), np.array(labels), label_to_int\n",
    "\n",
    "# Load the dataset and extract features\n",
    "data_dir = 'images/'\n",
    "features, labels, label_to_int = load_data_transformer(data_dir)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.08153478056192398\n",
      "Epoch [20/100], Loss: 0.02065344713628292\n",
      "Epoch [30/100], Loss: 0.007428711745887995\n",
      "Epoch [40/100], Loss: 0.002986220410093665\n",
      "Epoch [50/100], Loss: 0.0012519218726083636\n",
      "Epoch [60/100], Loss: 0.0005350172286853194\n",
      "Epoch [70/100], Loss: 0.00023170700296759605\n",
      "Epoch [80/100], Loss: 0.00010199053213000298\n",
      "Epoch [90/100], Loss: 4.6120385377435014e-05\n",
      "Epoch [100/100], Loss: 2.1884019588469528e-05\n",
      "Mean-per-class accuracy: 94.05%\n"
     ]
    }
   ],
   "source": [
    "# Define the PyTorch linear classifier\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Create and train the linear classifier\n",
    "num_classes = len(np.unique(labels))\n",
    "input_size = X_train.shape[1]\n",
    "classifier = LinearClassifier(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i + batch_size]\n",
    "        y_batch = y_train[i:i + batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = classifier(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = classifier(X_test)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "    correct = (predicted == y_test).sum().item()\n",
    "\n",
    "mean_per_class_accuracy = correct / y_test.size(0)\n",
    "print(f\"Mean-per-class accuracy: {mean_per_class_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Swin Transformer is a hierarchical Vision Transformer that introduces several improvements over the original Vision Transformer (ViT) design. Key enhancements include shifted window-based self-attention and a local relative position bias. The selected model, swin_tiny_patch4_window7_224, is a small version of the Swin Transformer architecture, which offers reduced computational complexity and fewer parameters while maintaining competitive performance. Swin Transformers are generally expected to outperform CNNs like ResNet-50 on large-scale datasets, as they can better capture long-range dependencies and learn hierarchical representations in input images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Vision Transformer, specifically the Swin Transformer, achieved a higher mean-per-class accuracy of 94.05% compared to the CNN (ResNet-50) at 74.3%. This indicates that the Swin Transformer performs better in this image classification task on the Oxford Pet Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Bengal': 10, 'British': 10, 'staffordshire': 10, 'Ragdoll': 9, 'american': 8, 'Russian': 8, 'Egyptian': 4, 'boxer': 4, 'miniature': 4, 'Abyssinian': 3, 'Maine': 3, 'Birman': 3, 'Bombay': 2, 'english': 2, 'Persian': 2, 'keeshond': 1, 'german': 1, 'Siamese': 1, 'saint': 1, 'samoyed': 1, 'chihuahua': 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_indices_trans = np.where(predicted != y_test)[0]\n",
    "misclassified_predicted_labels = predicted[misclassified_indices_trans]\n",
    "misclassified_ground_truth_labels = y_test[misclassified_indices_trans]\n",
    "int_to_label = {v: k for k, v in label_to_int.items()}\n",
    "\n",
    "misclassified_ground_truth_labels_names = [int_to_label[label.item()] for label in misclassified_ground_truth_labels]\n",
    "misclassified_predicted_labels_names = [int_to_label[label.item()] for label in misclassified_predicted_labels]\n",
    "\n",
    "ground_truth_label_counts_trans = Counter(misclassified_ground_truth_labels_names)\n",
    "predicted_label_counts_trans = Counter(misclassified_predicted_labels_names)\n",
    "print(ground_truth_label_counts_trans)\n",
    "len(ground_truth_label_counts_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import resnet50, ResNet50_Weights, ResNet18_Weights, ResNet34_Weights\n",
    "\n",
    "# Load data\n",
    "def load_data_cnn(data_dir):\n",
    "    # Load a pre-trained CNN model\n",
    "    cnn = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "    # Remove the final softmax layer\n",
    "    cnn = torch.nn.Sequential(*(list(cnn.children())[:-1]))\n",
    "\n",
    "    # Define image transformations\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    label_to_int = {}\n",
    "    current_label_int = 0\n",
    "\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(data_dir, filename)\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = data_transforms(image)\n",
    "            image = image.unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "            with torch.no_grad():\n",
    "                feature = cnn(image).numpy().flatten()  # Extract features\n",
    "\n",
    "            features.append(feature)\n",
    "            label = filename.split('.')[0].split('_')[0]\n",
    "\n",
    "            if label not in label_to_int:\n",
    "                label_to_int[label] = current_label_int\n",
    "                current_label_int += 1\n",
    "\n",
    "            labels.append(label_to_int[label])\n",
    "\n",
    "    features = normalize(features, axis=1)  # Normalize the features\n",
    "    return np.array(features), np.array(labels), label_to_int\n",
    "\n",
    "# Load the dataset and extract features\n",
    "data_dir = 'images/'\n",
    "features, labels, label_to_int = load_data_cnn(data_dir)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 2.3351\n",
      "Epoch [20/100], Loss: 1.6042\n",
      "Epoch [30/100], Loss: 1.1577\n",
      "Epoch [40/100], Loss: 0.8653\n",
      "Epoch [50/100], Loss: 0.6621\n",
      "Epoch [60/100], Loss: 0.5154\n",
      "Epoch [70/100], Loss: 0.4066\n",
      "Epoch [80/100], Loss: 0.3242\n",
      "Epoch [90/100], Loss: 0.2610\n",
      "Epoch [100/100], Loss: 0.2120\n",
      "Mean-per-class accuracy: 74.49%\n"
     ]
    }
   ],
   "source": [
    "# Define the PyTorch linear classifier\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Create and train the linear classifier\n",
    "num_classes = len(np.unique(labels))\n",
    "input_size = X_train.shape[1]\n",
    "classifier = LinearClassifier(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i + batch_size]\n",
    "        y_batch = y_train[i:i + batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = classifier(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate the linear classifier on the test set\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = classifier(X_test)\n",
    "    _, y_pred = torch.max(outputs, 1)\n",
    "    accuracy = (y_pred == y_test).sum().item() / len(y_test)\n",
    "\n",
    "print(f\"Mean-per-class accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'american': 33, 'staffordshire': 33, 'Bengal': 24, 'Russian': 22, 'Abyssinian': 20, 'Ragdoll': 19, 'Bombay': 17, 'boxer': 17, 'english': 13, 'Egyptian': 12, 'leonberger': 12, 'Persian': 11, 'Maine': 11, 'Siamese': 11, 'British': 11, 'Birman': 10, 'shiba': 10, 'chihuahua': 8, 'havanese': 8, 'newfoundland': 8, 'miniature': 8, 'wheaten': 7, 'scottish': 6, 'great': 6, 'yorkshire': 6, 'beagle': 6, 'basset': 5, 'german': 4, 'japanese': 4, 'saint': 3, 'keeshond': 3, 'pomeranian': 3, 'samoyed': 2, 'Sphynx': 2, 'pug': 2})\n",
      "Counter({'Bengal': 10, 'British': 10, 'staffordshire': 10, 'Ragdoll': 9, 'american': 8, 'Russian': 8, 'Egyptian': 4, 'boxer': 4, 'miniature': 4, 'Abyssinian': 3, 'Maine': 3, 'Birman': 3, 'Bombay': 2, 'english': 2, 'Persian': 2, 'keeshond': 1, 'german': 1, 'Siamese': 1, 'saint': 1, 'samoyed': 1, 'chihuahua': 1})\n"
     ]
    }
   ],
   "source": [
    "misclassified_indices_cnn = np.where(y_pred != y_test)[0]\n",
    "misclassified_predicted_labels = y_pred[misclassified_indices_cnn]\n",
    "misclassified_ground_truth_labels = y_test[misclassified_indices_cnn]\n",
    "int_to_label = {v: k for k, v in label_to_int.items()}\n",
    "\n",
    "misclassified_ground_truth_labels_names = [int_to_label[label.item()] for label in misclassified_ground_truth_labels]\n",
    "misclassified_predicted_labels_names = [int_to_label[label.item()] for label in misclassified_predicted_labels]\n",
    "\n",
    "ground_truth_label_counts_cnn = Counter(misclassified_ground_truth_labels_names)\n",
    "predicted_label_counts_cnn = Counter(misclassified_predicted_labels_names)\n",
    "print(ground_truth_label_counts_cnn)\n",
    "print(ground_truth_label_counts_trans)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the transformer classifies all categories better compared to the CNN. The categories where the models compare similarly are \"British\", \"keeshond\", and \"samoyed\" where the number of misclassified images are similar.\n",
    "\n",
    "The code cell below computes the indices where transformer wrong/cnn right, transformer right/cnn wrong, transformer wrong/cnn wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes = set()\n",
    "for trans in misclassified_indices_trans:\n",
    "    for cnn in misclassified_indices_cnn:\n",
    "        if trans == cnn:\n",
    "            dupes.add(trans)\n",
    "\n",
    "trans_wrong = []\n",
    "for trans in misclassified_indices_trans:\n",
    "    if trans not in dupes:\n",
    "        trans_wrong.append(trans)\n",
    "\n",
    "cnn_wrong = []\n",
    "for cnn in misclassified_indices_cnn:\n",
    "    if cnn not in dupes:\n",
    "        cnn_wrong.append(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Russian': 7, 'British': 3, 'Abyssinian': 2, 'pomeranian': 2, 'Birman': 2, 'Ragdoll': 2, 'staffordshire': 2, 'american': 2, 'Bengal': 2, 'boxer': 1, 'Bombay': 1, 'Persian': 1, 'scottish': 1, 'Siamese': 1, 'Egyptian': 1, 'chihuahua': 1})\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "trans_wrong_labels = predicted[trans_wrong]\n",
    "trans_wrong_names = [int_to_label[label.item()] for label in trans_wrong_labels]\n",
    "print(Counter(trans_wrong_names))\n",
    "print(len(trans_wrong_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'British': 25, 'Bengal': 23, 'american': 19, 'newfoundland': 17, 'english': 16, 'boxer': 14, 'Russian': 14, 'Maine': 14, 'Birman': 13, 'Siamese': 12, 'miniature': 10, 'Persian': 10, 'samoyed': 9, 'german': 9, 'beagle': 8, 'chihuahua': 8, 'wheaten': 8, 'Sphynx': 8, 'Ragdoll': 8, 'keeshond': 8, 'pomeranian': 7, 'staffordshire': 7, 'havanese': 7, 'Egyptian': 6, 'Abyssinian': 5, 'leonberger': 5, 'Bombay': 5, 'pug': 5, 'saint': 4, 'yorkshire': 4, 'basset': 4, 'great': 3, 'scottish': 3, 'shiba': 2})\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "cnn_wrong_labels = y_pred[cnn_wrong]\n",
    "cnn_wrong_names = [int_to_label[label.item()] for label in cnn_wrong_labels]\n",
    "print(Counter(cnn_wrong_names))\n",
    "print(len(cnn_wrong_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'american': 14, 'Birman': 6, 'chihuahua': 4, 'British': 4, 'Bengal': 3, 'Ragdoll': 3, 'Maine': 3, 'Abyssinian': 3, 'Egyptian': 3, 'miniature': 2, 'Siamese': 2, 'german': 2, 'staffordshire': 2, 'great': 1, 'Bombay': 1, 'saint': 1, 'boxer': 1, 'Russian': 1, 'Sphynx': 1})\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "dupes_list = list(dupes)\n",
    "both_wrong = predicted[dupes_list]\n",
    "both_wrong_names = [int_to_label[label.item()] for label in both_wrong]\n",
    "print(Counter(both_wrong_names))\n",
    "print(len(both_wrong_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the results above, there are 31 images where the transformer gets it wrong and the cnn gets it right, out of the 31 images, most categories only occur once or twice except for the 'Russian' category where the transformer misclassifies images in the category 7 times and the cnn gets it right.\n",
    "\n",
    "There are 320 images where the cnn gets it wrong and the transformer gets it right. The categories that appear the most (>15 occurences) are 'British', 'Bengal', 'american', 'newfoundland', and 'english'. \n",
    "\n",
    "There are 57 images where both models get it wrong, the categories that appear the most are 'american' and 'Birman', the rest have less than 5 occurences."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Problem 6 - BatchNorm - Investigations (10 bonus points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_i = w^T h_i +b$\n",
    "\n",
    "Batch Norm: $\\^{x_i} = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2+\\epsilon}}$\n",
    "\n",
    "where $\\mu_B = \\frac{1}{m}\\sum_{i=1}^m x_i$ and $\\sigma_B^2 = \\frac{1}{m}\\sum_{i=1}^m(x_i - \\mu _B)^2$\n",
    "\n",
    "We can substitute:\n",
    "\n",
    "$\\^{x_i} = \\frac{(w^T h_i + b) - \\frac{1}{m}\\sum_{i=1}^m (w^T h_i + b)}{\\sqrt{\\frac{1}{m}\\sum_{i=1}^m(x_i - \\mu_B)^2 + \\epsilon}}$\n",
    "\n",
    "$\\^{x_i} = \\frac{w^T h_i + (b - \\frac{1}{m}\\sum_{i=1}^m (w^T h_i + b))}{\\sqrt{\\frac{1}{m}\\sum_{i=1}^m(x_i - \\mu_B)^2 + \\epsilon}}$\n",
    "\n",
    "$\\^{x_i} = \\frac{w^T h_i}{\\sqrt{\\frac{1}{m}\\sum_{i=1}^m(x_i - \\mu _b)^2 + \\epsilon}} +  \\frac{(b - \\frac{1}{m}\\sum_{i=1}^m)}{\\sqrt{\\frac{1}{m}\\sum_{i=1}^m(x_i - \\mu _b)^2 + \\epsilon}}$\n",
    "\n",
    "$\\^{x_i} = \\frac{w^T h_i}{\\sqrt{\\frac{1}{m}\\sum_{i=1}^m(x_i - \\mu _b)^2 + \\epsilon}} +  \\frac{(b - \\frac{1}{m}\\sum_{i=1}^m)}{\\sqrt{\\frac{1}{m}\\sum_{i=1}^m(x_i - \\mu _b)^2 + \\epsilon}}$\n",
    "\n",
    "$\\^{x_i} = \\frac{w^T}{\\sqrt{\\sigma_B^2+\\epsilon}}h_i + \\frac{b - \\mu_B}{\\sqrt{\\sigma_B^2+\\epsilon}}$\n",
    "\n",
    "$\\^{x_i} = \\frac{w^T}{\\sqrt{\\sigma_B^2+\\epsilon}}h_i + (\\frac{b}{\\sqrt{\\sigma_B^2+\\epsilon}} - \\frac{\\mu_B}{\\sqrt{\\sigma_B^2+\\epsilon}})$\n",
    "\n",
    "The first term is the new weight and the second term (second + third term) is the new noise. Therefore we can see that using batch normalization we have a bias term $-\\frac{\\mu_B}{\\sqrt{\\sigma_B^2+\\epsilon}}$ so don't need an additional bias term in the neural network architecture and we can see that the weight is scaled by $\\frac{1}{\\sqrt{\\sigma_B^2+\\epsilon}}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. ChatGPT\n",
    "2. https://stats.stackexchange.com/questions/304755/pros-and-cons-of-weight-normalization-vs-batch-normalization\n",
    "3. https://medium.com/thecyphy/train-cnn-model-with-pytorch-21dafb918f48\n",
    "4. https://huggingface.co/timm/swin_tiny_patch4_window7_224.ms_in22k\n",
    "5. https://github.com/huggingface/pytorch-image-models\n",
    "6. https://www.kaggle.com/datasets/nachiket273/visiontransformerpretrainedimagenet1kweights\n",
    "7. https://pytorch.org/vision/stable/models/swin_transformer.html\n",
    "8. https://github.com/berniwal/swin-transformer-pytorch\n",
    "9. https://www.reddit.com/r/MachineLearning/comments/ti0u6i/d_complete_guide_of_swin_transformer_with_full/\n",
    "10. https://www.kaggle.com/code/residentmario/batch-normalization-and-its-successors/notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
